replicaCount: 1

# nodeSelector -- Node labels for pod assignment
nodeSelector:
  NodeGroupType: ${node_group_type}
  kubernetes.io/os: ${operating_system}

webhook:
  # -- Enable webhook server
  enable: true
  # -- Webhook service port
  port: 8080

# resources -- Pod resource requests and limits
# Note, that each job submission will spawn a JVM within the Spark Operator Pod using "/usr/local/openjdk-11/bin/java -Xmx128m".
# Kubernetes may kill these Java processes at will to enforce resource limits. When that happens, you will see the following error:
# 'failed to run spark-submit for SparkApplication [...]: signal: killed' - when this happens, you may want to increase memory limits.
resources:
   limits:
     cpu: 200m
     memory: 1Gi
   requests:
     cpu: 100m
     memory: 512Mi

batchScheduler:
  # -- Enable batch scheduler for spark jobs scheduling. If enabled, users can specify batch scheduler name in spark application
  enable: true
